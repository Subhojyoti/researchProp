In this appendix, we show the different experiments carried on various test-beds. Appendix A contains experiments on ClusUCB while Appendix B contains experiment on AugUCB.

\subsection*{Appendix A}
\label{AppendixA}
For the purpose of performance comparison using cumulative regret as the metric, we implement the following algorithms:  KL-UCB\cite{garivier2011kl}, DMED\cite{honda2010asymptotically}, MOSS\cite{audibert2009minimax}, UCB1\cite{auer2002finite}, UCB-Improved\cite{auer2010ucb}, Median Elimination\cite{even2006action}, Thompson Sampling(TS)\cite{agrawal2011analysis} and UCB-V\cite{audibert2009exploration}\footnote{The implementation for KL-UCB and DMED were taken from \cite{CapGarKau12}}. The parameters of ClusUCB algorithm for all the experiments are set as follows: $\psi=\log T$, $\rho_{s}=\frac{1}{2^{2m+1}}$ and $\rho_{a}=\frac{1}{2^{4m+1}}$ for $m=0,1,..., \lfloor \frac{1}{2}\log_{2} \frac{T}{e}\rfloor$. So in all the experiments $\rho_{a}$ and $\rho_{s}$ are initialized to $1$ and then reduced after every round. By this definition of $\rho_{a},\rho_{s}$ we have made sure that their value always remain bounded $\in(0,1]$. When $K$ is large and $p$ is small it is advantageous to run $\rho_{a} < \rho_{s}$ because this will aggressively eliminate arms within each cluster while full cluster elimination will be more conservative. 

\begin{figure*}
\centering
  %\begin{tabular}{ccc}
%%%%% expt1  
  %\begin{subfigure}{0.32\textwidth}
 %\tabl{c}{\scalebox{0.6}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Cumulative regret},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north,legend columns=3} ]  
  % UCB    

\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/UCB_Vcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/DMEDcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/KLUCBcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/MOSScomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/UCB1comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/TScomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt1/clUCBcomp_subsampled.txt};
      \legend{UCB-V,DMED,KL-UCB,MOSS,UCB1,TS,ClusUCB(p=4)}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $1$: $20$ Bernoulli-distributed arms with $r_{i_{{i}\neq {*}}}=0.07$ and $r^{*}=0.1$.}
  \label{fig:1}
  %\end{subfigure}
	%&
	%%%%%%% Expt 2
	  %\begin{subfigure}{0.32\textwidth}
 %\tabl{c}{\scalebox{0.6}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Cumulative regret},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north,legend columns=3} ]
      % UCB
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/clUCBNCcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/clUCBCcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/Med_Elimcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/UCB_Improvedcomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/MOSScomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt2/UCB1comp_subsampled.txt};
      \legend{ClusUCB-AE(p=1),ClusUCB(p=20),Med-Elim,UCB-Improved,MOSS,UCB1}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $2$: $100$ Gaussian-distributed arms with $r_{i_{{i}\neq {*}:1-33}}=0.01$, $r_{i_{{i}\neq {*}:34-99}}=0.06$ and $r^{*}_{i=100}=0.1$.}
  \label{fig:2}
  %\end{subfigure}
	%&
	\end{figure*}		
	
	\begin{figure*}
	\centering
	%%%%%%% Expt 3
	  %\begin{subfigure}{0.32\textwidth}
 %\tabl{c}{\scalebox{0.6}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={Arms},
	ylabel={Cumulative regret},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north,legend columns=-1} ]
      % UCB
%\addplot table[x index=0,y index=1,col sep=tab] {results/Expt3/clUCB20_500.txt};
\addplot table[x index=0,y index=1,col sep=tab] {results/Expt3/clUCB20_500_1.txt};
\addplot table[x index=0,y index=1,col sep=tab] {results/Expt3/MOSS20_500.txt};
      \legend{ClusUCB(p=K/10),MOSS}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $3$: $20$ to $500$ Bernoulli-distributed arms with $r_{i_{{i}\neq {*}}}=0.05$ and $r^{*}=0.1$.}
  \label{fig:3}
  %\end{subfigure}
  %\end{tabular}
%\caption{Cumulative regret for various bandit algorithms on three stochastic K-armed bandit environments. }
\label{fig:karmed}
\end{figure*}



%\begin{figure}[!tbp]
%\label{fig:1}
%\begin{minipage}[b]{0.5\textwidth}
%\includegraphics[width=\textwidth]{img/ClusUCB_variousAlgo.png}
%
%\caption{Experiment 1: Regret for various Algorithms. $T=60000$}
%\end{minipage}
%\end{figure}
%
%\hspace{0.1em}
%
%\begin{figure}[!tbp]
%\label{fig:2}
%\begin{minipage}[b]{0.5\textwidth}
%
%\includegraphics[width=\textwidth]{img/clusUCB_variousAlgo(expt2)_Final.png}
%\caption{Experiment 2: Regret for various Algorithms. $T=2\times 10^{6}$}
%\end{minipage}
%\end{figure}
%
%\hspace{0.1em}
%
%\begin{figure}[!tbp]
%\label{fig:3}
%\begin{minipage}[b]{0.5\textwidth}
%\includegraphics[width=\textwidth]{img/clUCB_MOSS_expt3.png}
%\caption{Experiment 3: Regret Growth for ClusUCB and MOSS . $T=10^{5} + K^{2}\times 10^{4}$ for $K=20$ to $200$}
%\end{minipage}
%\end{figure}
%
%\hspace{0.1em}
%


%In the stochastic bandit literature there are several powerful algorithms with and without proven regret bounds. Algorithms like $\epsilon$-greedy(\cite{sutton1998reinforcement}) or softmax(\cite{sutton1998reinforcement}) or UCB-Tuned(\cite{auer2002finite}) has no proven regret bounds. Again algorithms like UCB-$\delta$(\cite{abbasi2011improved}) with proven regret bound better than UCB1  falls within the realm of fixed confidence setting whereas one has to provide the probability of error $\delta$. We also make a distinction between frequentist based approach like the UCB algorithms and the Bayesian approach like the Thompson Sampling(\cite{agrawal2011analysis}). 
% The intuition here is that since each cluster contains a large number of arms it should be eliminated less aggressively. 

%For parameter settings of ClusUCB and further experiments see Appendix \ref{App:Further:Expt}.

The first experiment is conducted over a testbed of $20$ arms for the test-cases involving Bernoulli reward distribution with expected rewards of the arms $r_{i_{{i}\neq {*}}}=0.07$ and $r^{*}=0.1$. These type of cases are frequently encountered in web-advertising domain. The horizon $T$ is set to $60000$. After limited exploratory experimentation the number of clusters $p$ for ClusUCB is set to $4$. The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:1}. 
ClusUCB, MOSS, UCB1, UCB-V, KL-UCB, TS and DMED are run in this experimental setup and we observe that ClusUCB performs better than all the aforementioned algorithms. Because of the short horizon $T$, we do not implement UCB-Improved and Median Elimination on this test-case. We also observe that in this case the cumulative regret of ClusUCB and TS are very similar to each other with ClusUCB being slightly better.

	The second experiment is conducted over a testbed of $100$ arms involving Gaussian reward distribution with expected rewards of the arms $r_{i_{{i}\neq {*}:1-33}}=0.01$, $r_{i_{{i}\neq {*}:34-99}}=0.06$ and $r^{*}_{i=100}=0.1$ with variance set at $\sigma = 0.3,\forall i\in A$. The horizon $T$ is set for a large duration of $2\times 10^{6}$ and the number of clusters $p=20$. The regret is averaged over $100$ independent runs and is shown in Figure \ref{fig:2}. In this case, in addition to ClusUCB, we also show the performance of no-clustering version of ClusUCB algorithm (i.e., $p=1$).   From the results in Figure \ref{fig:2}, we observe that ClusUCB with $p=20$ outperforms ClusUCB with $p=1$ as well as MOSS, UCB1, UCB-Improved and Median-Elimination($\epsilon=0.03,\delta=0.1$). We also observed that the ClusUCB variant that uses only  the arm elimination condition in Algorithm \ref{alg:clusucb} performs worse than the variant that employs both cluster and arm elimination conditions. Also the performance of UCB-
Improved is poor in comparison to other algorithms, which is probably because of pulls wasted in initial exploration.

	The third experiment is conducted over a testbed of $20-500$ (interval of $10$) arms with Bernoulli reward distribution, where the expected rewards of the arms are $r_{i_{{i}\neq {*}}}=0.05$ and $r^{*}=0.1$. The horizon $T$ is set to $10^{5} + K^{2}\times 10^{4}$ and the number of arms are increased from $K=20$ to $500$. The proposed algorithm ClusUCB is run with $p=K/10$. The regret is averaged over $500$ independent runs and is shown in Figure \ref{fig:3}. We report the performance of MOSS and ClusUCB only over this setup. From the results in Figure \ref{fig:3}, it is evident that the growth of regret for ClusUCB is lower than that of MOSS. 

\begin{figure}
\centering
  %\begin{tabular}{c}
  %&
  %%%%%%Expt4
  %\begin{subfigure}{0.45\textwidth}
 %\tabl{c}{\scalebox{0.7}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Cumulative regret},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north, legend columns=4} ]
      % UCB
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/clUCB1comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/clUCB2comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/clUCB3comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/MOSScomp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/clUCB4comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/clUCB5comp_subsampled.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/Expt4/TScomp_subsampled.txt};
      \legend{ClusUCB(1A),ClusUCB(4B),ClusUCB(10B),MOSS,ClusUCB(5S),ClusUCB(10S),TS}
      %\legend{ClusUCB (NC, p=1),ClusUCB (C, p=4),ClusUCB(C, p=10) ,MOSS, ClusUCB(C, p=5, NAE), ClusUCB(C, p=10, NAE)}
      %\legend{ClusUCB(1,A),ClusUCB(4,B),ClusUCB(10,B), MOSS,ClusUCB(5,S), ClusUCB(10,A)}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $4$: Cumulative regret for ClusUCB variants: $1,4,5,10$ correspond to number $p$ of clusters and A, S, B correspond to having only arm elimination, only cluster elimination and having both in Algorithm \ref{alg:clusucb}. For using just cluster elimination in ClusUCB, we stop when we left with only one cluster and play the max payoff arm of that cluster for the remaining time horizon. }
  \label{Fig:variousClus}
  %\end{subfigure}
  %\end{tabular}
\end{figure}


	The fourth experiment is performed over a testbed having $20$ Bernoulli-distributed arms with $r_{i_{:{{i}\neq {*}}}}=0.06,\forall i\in A$ and $r^{*}=0.1$. In Figure \ref{Fig:variousClus}, we report the results with $T=60000$ averaged over $100$ independent runs for ClusUCB with  $p=\lbrace 1,4,10\rbrace$. Also, in this experiment we take $\psi = 1$ to make sure that the exploration is low. Under these conditions, exploration is low and the elimination parameters are decreased very fast. This leads to a greater number of errors committed by ClusUCB-AE that is ClusUCB($p=1$). Two other benchmark algorithms are considered here, MOSS which is one of our main competitors and TS which has performed near equivalently in experiment $1$(see Fig \ref{fig:1}). In this case we see that, since $\rho_{a}$ is decreased very fast, the optimal arm $a^{*}$ gets eliminated most of the time for no clustering $p=1$. While a balance of $p,\rho_{a}$ and $\rho_{s}$ gives a much better result. ClusUCB with $p=4$ and $10$ 
perform better than MOSS, while $p=1$ with just arm elimination does not converge and $p=5,10$ with just Cluster elimination and no arm elimination also does not converge, implying both cluster and arm elimination are necessary. This also concurs with the theoretical observations. Note also that ClusUCB($p=4$) outperforms TS in this setup.	

\subsection*{Appendix B}
\label{AppendixB}
\begin{figure}
\centering
  %\begin{tabular}{c}
  %&
  %%%%%%Expt4
  %\begin{subfigure}{0.45\textwidth}
 %\tabl{c}{\scalebox{0.7}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Error Percentage},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north, legend columns=4} ]
      % UCB
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/APT.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/AugUCB.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/UA.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/UCBE_1.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/UCBE_256.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestAP/UCBE_1_4.txt};
      \legend{APT,AugUCBE,Unif Alloc,UCBE(1),UCBE(256),UCBE($\frac{1}{4}$)}
      %\legend{ClusUCB (NC, p=1),ClusUCB (C, p=4),ClusUCB(C, p=10) ,MOSS, ClusUCB(C, p=5, NAE), ClusUCB(C, p=10, NAE)}
      %\legend{ClusUCB(1,A),ClusUCB(4,B),ClusUCB(10,B), MOSS,ClusUCB(5,S), ClusUCB(10,A)}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $1$: Threshold Bandit with Arithmetic Progression}
  \label{Fig:budgetExpt1}
  %\end{subfigure}
  %\end{tabular}
\end{figure}

	In this section we compare the empirical performance of AugUCB against APT, Unifirm Allocation and UCBE algorithm. The first experiment is conducted on a testbed of $10$ arms involving Bernoulli reward distribution with expected rewards of the arms $r_{1:4}=0.2+(0:3)*0.05$, $r_{5}=0.45$, $r_{6}=0.55$ and $r_{7:10}=0.65+(0:3)*0.05$. The means are set as arithmetic progression. The threshold $\tau$ is set at $0.5$. Each algorithm is run independently a $1000$ times for $500$ timesteps and the output set of arms suggested by the algorithms at every timestep is recorded. The output is considered erroneous if the correct set of arms is not $i=\lbrace 6,7,8,9,10 \rbrace$. The error percentage over $1000$ runs is plotted against $500$ timesteps. For the uniform allocation algorithm, for each $t=1,2,..,T$ the arms are sampled uniformly. For UCBE (\cite{audibert2009exploration}) algorithm which was built for single best arm identification, we modify it according to \cite{locatelli2016optimal} to suit the goal of finding arms above the threshold $\tau$. So the exploration parameter $a$ in UCBE is set to $a_{i}=4^{i}\dfrac{T-K}{H}$ for $i\in \lbrace -1,0,4 \rbrace$ and $H=\sum_{i=1}^{K}\dfrac{1}{\Delta_{i}^{2}}$ is defined as the problem complexity. In this experiment we see that AugUCB performs better than all the other algorithms mentioned. Only UCBE($1$) catches up with AugUCB and that is because it has access to the exact problem complexity. The result is shown in Figure \ref{Fig:budgetExpt1}.
	
\begin{figure}
\centering
  %\begin{tabular}{c}
  %&
  %%%%%%Expt4
  %\begin{subfigure}{0.45\textwidth}
 %\tabl{c}{\scalebox{0.7}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Error Percentage},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north, legend columns=4} ]
      % UCB
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/APT.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/AugUCB.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/UA.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/UCBE_1.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/UCBE_256.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGP/UCBE_1_4.txt};
      \legend{APT,AugUCBE,Unif Alloc,UCBE(1),UCBE(256),UCBE($\frac{1}{4}$)}
      %\legend{ClusUCB (NC, p=1),ClusUCB (C, p=4),ClusUCB(C, p=10) ,MOSS, ClusUCB(C, p=5, NAE), ClusUCB(C, p=10, NAE)}
      %\legend{ClusUCB(1,A),ClusUCB(4,B),ClusUCB(10,B), MOSS,ClusUCB(5,S), ClusUCB(10,A)}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $2$: Threshold Bandit with Geometric Progression }
  \label{Fig:budgetExpt2}
  %\end{subfigure}
  %\end{tabular}
\end{figure}

	The second experiment is conducted on a testbed of $10$ arms with the means set as Geometric Progression. The testbed involves Bernoulli reward distribution with expected rewards of the arms as $r_{1:4}=0.4-(0.2)^{1:4}$, $r_{5}=0.45$, $r_{6}=0.55$ and $r_{7:10}=0.6+(0.2)^{5-(1:4)}$. AugUCB, APT, Uniform Allocation and UCBE with the same settings  as experiment $1$ are run on this testbed. The result is shown in Figure \ref{Fig:budgetExpt2}. Here, we see that AugUCB beats APT with only UCBE($1$) performing at par with AugUCB. 

\begin{figure}
\centering
  %\begin{tabular}{c}
  %&
  %%%%%%Expt4
  %\begin{subfigure}{0.45\textwidth}
 %\tabl{c}{\scalebox{0.7}{
 \begin{tikzpicture}
      \begin{axis}[
	xlabel={timestep},
	ylabel={Error Percentage},
       clip mode=individual,grid,grid style={gray!30},
  legend style={at={(0.5,-0.2)},anchor=north, legend columns=4} ]
      % UCB
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/APT.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/AugUCB.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/UA.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/UCBE_1.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/UCBE_256.txt};
\addplot table[x index=0,y index=1,col sep=tab,each nth point={10}] {results/budgetTestGR/UCBE_1_4.txt};
      \legend{APT,AugUCBE,Unif Alloc,UCBE(1),UCBE(256),UCBE($\frac{1}{4}$)}
      %\legend{ClusUCB (NC, p=1),ClusUCB (C, p=4),ClusUCB(C, p=10) ,MOSS, ClusUCB(C, p=5, NAE), ClusUCB(C, p=10, NAE)}
      %\legend{ClusUCB(1,A),ClusUCB(4,B),ClusUCB(10,B), MOSS,ClusUCB(5,S), ClusUCB(10,A)}
      \end{axis}
      \end{tikzpicture}
      %}\\}
			\caption{Experiment $3$: Threshold Bandit with $3$ Group Setting }
  \label{Fig:budgetExpt3}
  %\end{subfigure}
  %\end{tabular}
\end{figure}

	The third experiment is conducted on a testbed of $10$ arms with the means divided into $3$ groups. Again the testbed involves Bernoulli reward distribution with expected rewards of the arms as $r_{1:3}=0.1$, $r_{4:7}=\lbrace 0.35,0.45,0.55,0.65\rbrace$ and $r_{8:10}=0.9$. AugUCB, APT, Uniform Allocation and UCBE with the same settings as experiment $1$ are run on this testbed. The result is shown in Figure \ref{Fig:budgetExpt3}. Here, we see that AugUCB beats APT.  
